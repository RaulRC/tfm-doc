\chapter{Introducción}
\label{chap:Introduccion}
\renewcommand{\tablename}{Tabla}
\section{Contexto del proyecto}

\drop{E}{n} \cite{bernerslee2001semantic} se define la Web Semántica como
un tipo de Web cuyo contenido resulta procesable de manera automática. Para
conseguir un contenido procesable se debe antes llevar a cabo una
representación o formalización del conocimiento que se pretende exponer. Esto ha
sido posible gracias al concepto de \textit{tripla}
que no es más que la relación, expresada en un lenguaje formal, existente entre un sujeto y un objeto a través de
un predicado que los relaciona. De esta manera, si se desea expresar formalmente una sentencia
respecto de cualquier concepto bastará con establecer un sujeto o recurso (el
propio concepto) una relación o propiedad que se desee modelar, y un objeto que
a su vez puede ser un nuevo recurso de manera que agrupando conjuntos de triplas
se logra definir conceptos completos de manera formal. 


Durante los últimos años se han desarrollado lenguajes como \acs{RDF} y
\acs{OWL}, y
especificaciones, con el fin de dar soporte a 
la interoperabilidad semántica \cite{Shadbolt:2006:SWR:1155313.1155373}. En
1997 el \acf{W3C} ~\cite{W3CSW} define la primera especificación de \acs{RDF} lo que sentará los cimientos de la Web Semántica: el
objetivo de \acs{RDF} será aportar una descripción semántica del conocimiento en la
Web \cite{Shadbolt:2006:SWR:1155313.1155373} como lenguaje de definición de
recursos, haciendo posible trabajar con la totalidad de la Web
como un conjunto de recursos y sus interrelaciones. 

Posteriormente surge el paradigma Linked Data \cite{bernerslee:2009}, que se puede definir
como el uso del modelo Web para publicar datos estructurados de manera que
puedan ser fácilmente consumidos y combinados con otros ~\cite{bizer_linked_2009}. Valiéndose del concepto
de \acf{URI}, se consiguen identifcar recursos en la red de forma unívoca y así
poder enlazarlos sin ambigüedad. Linked Data
aprovecha la potencia descriptiva de \acs{RDF} para facilitar el procesado
y razonamiento automático sobre grandes conjuntos de datos. En
\cite{bernerslee:2009} se enumera una serie de principios que deben cumplir los
datos para ser considerados Linked Data: 


\begin{enumerate}
\item{Usar \acs{URI} como identificadores de los recursos publicados en la Web.}
\item{Usar las URL de estas \acs{URI} para que la gente pueda localizar y consultar
  estos recursos.}
\item{Proporcionar información útil cuando la \acs{URI} sea desreferenciada.}
\item{Incluir vínculos a otras \acs{URI} relacionadas con los datos en el recurso.}
\end{enumerate}


Por otra parte, el concepto de \textit{Calidad} puede aplicarse a cualquier tarea u objeto. Es
importante matizar para el contexto del proyecto qué se entiende por calidad y
más concretamente por calidad de los datos (\acs{DQ}). 


Existen varias definiciones de calidad que conviene considerar a la hora de
abordar el proyecto. Se entiende como calidad a: 

\textit{Propiedad o conjunto de propiedades
  inherentes a algo que permiten juzgar su valor}.

Sin embargo este concepto ha ido variando con el tiempo, adaptándose a las
necesidades y a los procesos. Relacionando este concepto con la
\textit{fabricación} de un determinado bien, en ~\cite{ISHI} se define la calidad
como: 

\textit{Un producto tiene calidad cuando es desarrollado, diseñado y mantenido
  de la forma más económica, útil y satisfactoria para el consumidor}. 


Autores como \cite{conf/webist/CaballeroMACC} o \cite{conf/ekaw/FurberH10} dejan constancia de cómo la calidad de los datos resulta imprescindible en el
desarrollo con éxito de cualquier tarea o toma de decisión. Un nivel inadecuado de calidad en los datos puede tener impactos sustanciales en ámbitos
sociales y económicos. Las empresas están mejorando la calidad de los datos con
enfoques y herramientas prácticas \cite{Wang:1996:BAD:1189570.1189572}. 

En el ámbito de las tecnologías semánticas, la comunidad ha prestado poca
atención a la calidad de los datos que han sido representados mediante la
utilización de tecnologías semánticas
\cite{conf/ekaw/FurberH10}. Existen en la actualidad un número considerable de
frameworks disponibles para el desarrollo de aplicaciones basadas en el uso de
tecnologías semánticas, no obstante, ninguno de ellos incluye funcionalidades
específicas que permitan procesar una evaluación del nivel de calidad de los
datos que se están usando.

Puesto que ningún framework de desarrollo de Web Semántica facilita este tipo de
operaciones de medición, existe una necesidad de elaborar
mecanismos que permitan llevar a cabo evaluaciones de calidad de los datos
usados en aplicaciones de tecnologías semánticas.


Con la irrupción de las tecnologías Big Data y dadas las necesidades que existen
de procesamiento distribuido sobre grandes volúmenes de información, encontramos
que el problema de la evaluación de la calidad de los datos semánticos se
extiende a este ámbito, no pudiendo encontrar ningún framework que permita
trabajar la calidad de los datos semánticos de manera distribuida.



Siendo el problema la ausencia de herramientas que permitan el procesamiento
distribuido de datos semánticos y por otra parte la necesidad de llevar a cabo
evaluaciones de calidad sobre grandes volúmenes de datos semánticos, el objetivo del \acf{TFM}
consiste en el desarrollo de una capa tecnológica (stack) para uno de estos frameworks. La finalidad de
dicho stack será la de diseñar, implementar y poner a disposición de la
comunidad un conjunto de primitivas de evaluación de calidad de datos para uno de
los frameworks de desarrollo de aplicaciones de tecnología semántica más
importantes, Apache Jena, considerando el contexto en el que los
datos deben son usados mediante el uso de reglas que lo modelen y sean procesables.


\section{Evolución respecto del PFC}


Tras llevar a cabo un estudio acerca del estado actual de los frameworks de
desarrollo de Web Semántica y Linked Data, durante el desarrollo del \acf{PFC}
se escogió uno de ellos basado en
Java, \textbf{Apache Jena}, y se extendió con la finalidad de ofrecer estos
mecanismos para la evaluación de la calidad de datos semánticos.

Paralelamente, durante los últimos años han tenido lugar una serie de cambios muy
significativos
en la industria de las tecnologías de la información, tales como el nacimiento
del Internet
de las Cosas, Computación en la Nube y la aparición de las Redes Sociales.


El desarrollo y explotación de estas tecnologías ha propiciado que la cantidad
de los datos
que se generan por unidad de tiempo se haya incrementado a una velocidad sin
precedentes,
trayendo consigo la necesidad de cómputo de tales volúmenes de información
heterogénea,
en tiempos razonables y de manera escalable \cite{map_reduce}.

Esta necesidad ha propiciado la aparición de paradigmas, tecnologías y numerosos
frameworks con los que abordar esta problemática desde diferentes puntos de
vista (procesamiento por lotes, en tiempo real, extracción, transformación y
carga de datos, seguridad,\ldots), agrupándose en ecosistemas tal y como pueda
ser el caso del \textbf{ecosistema Hadoop} \cite{HADOOP-ecosystem}.

\textbf{Apache Spark} \cite{SPARK} es un framework de procesamiento distribuido,
perteneciente al ecosistema Hadoop, que en los últimos años se ha convertido en
el estándar \textit{de facto} a la hora de abordar problemas de procesamiento de
grandes volúmenes de información en tiempos razonables, obteniendo unos
resultados de rendimiento varios órdenes de magnitud superior frente a modelos y
tecnologías anteriores, debido al procesamiento en memoria.

Mientras que el proyecto de Jena ha ido evolucionando para permitir el
procesamiento de datos semánticos de manera cetralizada y habiendo estudiado el
estado actual de los frameworks de procesamiento distribuido, se concluye que
ninguno de ellos ofrece primitivas para el procesamiento de datos semánticos en
distribuido y por lo tanto, tampoco mecanismos para llevar a cabo cálculos de
métricas de calidad sobre datos semánticos en entornos distribuidos.

Debido a la necesidad de incluir primitivas de evaluación de calidad de los
datos a la hora de desarrollar cualquier tarea o toma de decisión y puesto que
el ritmo de crecimiento de los datos dificulta su análisis en tiempos
razonables, se establece como objetivo principal de este Trabajo Fin de Máster
ofrecer un stack tecnológico basado en un framework de procesamiento distribuido
para que permita llevar a cabo análisis de calidad de datos semánticos en
entornos Big Data.

Para el presente Trabajo fin de Máster, será \textbf{Apache Spark} el framework
sobre el cual se construirá dicho stack para dar soporte a primitivas de
evaluación de calidad de los datos de una manera distribuida, escalable y
tolerante a fallos.

Como incremento respecto al PFC, cabe destacar los siguientes aspectos:

\begin{enumerate}
  \item Elaboración de un stack tecnológico basado en un framework de desarrollo
    distribuido, \textbf{Apache Spark}, para permitir el procesado de datos RDF:
    \textbf{SparkRDF}. Este stack estará basado en el framework \textbf{Apache
      Jena} para el procesamiento de datos en formatos semánticos y en
    \textbf{Apache Spark} para ofrecer primitivas de procesamiento en
    distribuido.
  \item Extensión de dicho stack para permitir evaluación de calidad de datos
    semánticos de manera distribuida, \textbf{SparkDQ}.
  \item Elección o desarrollo de una ontología que describa evaluaciones de
    calidad de los datos.
  \item Desarrollo de primitivas de razonamiento sobre evaluaciones de
    calidad.
  \item Incremento del rendimiento a la hora de calcular métricas sobre
    grafos de datos enlazados.
  \item Estudio y comparativa entre resultados de \textbf{JenaDQ} y
    \textbf{SparkDQ} con el fin de establecer unos criterios de mejora
    en términos de tiempo y eficiencia a la hora de llevar a cabo
    estos cálculos de métricas de calidad.
  \item Elaboración de una prueba de concepto de extracción de
    grandes volúmenes de datos, evaluación y presentación de las
    métricas.
\end{enumerate}


\section{Logro de competencias planteadas}

A continuación se expone un listado de competencias planteadas:

\begin{itemize}
\item[\textbf{CE1}] Capacidad para la integración de tecnologías, aplicaciones, servicios
  y sistemas propios de la Ingeniería Informática, con carácter generalista, y
  en contextos más
amplios y multidisciplinares
\item[\textbf{CE2}] Capacidad para la planificación estratégica, elaboración, dirección,
coordinación,
y gestión técnica y económica en los ámbitos de la ingeniería informática
relacionados, entre otros, con: sistemas, aplicaciones, servicios, redes 
infraestructuras o instalaciones informáticas y centros o factorías de
desarrollo de
software, respetando el adecuado cumplimiento de los criterios de calidad y
medioambientales y en entornos de trabajo multidisciplinares.
\item[\textbf{CE3}] Capacidad para la dirección de proyectos de investigación,
  desarrollo e innovación, en empresas y centros tecnológicos, con garantía de
  la seguridad para
las personas y bienes, la calidad final de los productos y su homologación. 
\item [\textbf{CE4}] Capacidad para modelar, diseñar, definir la arquitectura, implantar,
gestionar,
operar, administrar y mantener aplicaciones, redes, sistemas, servicios y
contenidos informáticos.

\item[\textbf{CE5}] Capacidad de comprender y saber aplicar el funcionamiento y organización
de
Internet, las tecnologías y protocolos de redes de nueva generación, los modelos
de componentes, software intermediario y servicios.

\item[\textbf{CE6}] Capacidad para asegurar, gestionar, auditar y certificar la calidad de los
desarrollos, procesos, sistemas, servicios, aplicaciones y productos
informáticos.

\item[\textbf{CE7}] Capacidad para diseñar, desarrollar, gestionar y evaluar mecanismos de
certificación y garantía de seguridad en el tratamiento y acceso a la
información
en un sistema de procesamiento local o distribuido.

\item[\textbf{CE8}] Capacidad para analizar las necesidades de información que se plantean en
un
entorno y llevar a cabo en todas sus etapas el proceso de construcción de un
sistema de información.

\item[\textbf{CE9}] Capacidad para diseñar y evaluar sistemas operativos y servidores, y
aplicaciones
y sistemas basados en computación distribuida.

\item[\textbf{CE10}] Capacidad para comprender y poder aplicar conocimientos avanzados de
computación de altas prestaciones y métodos numéricos o computacionales a
problemas de ingeniería.
\item[\textbf{CE11}] Capacidad de diseñar y desarrollar sistemas, aplicaciones y servicios
informáticos
en sistemas empotrados y ubicuos.
\item[\textbf{CE12}] Capacidad para aplicar métodos matemáticos, estadísticos y de
inteligencia
artificial para modelar, diseñar y desarrollar aplicaciones, servicios, sistemas
inteligentes y sistemas basados en el conocimiento.
\item[\textbf{CE13}] Capacidad para utilizar y desarrollar metodologías, métodos, técnicas,
programas
de uso específico, normas y estándares de computación gráfica.

\item[\textbf{CE14}] Capacidad para conceptualizar, diseñar, desarrollar y evaluar la
interacción
persona-ordenador de productos, sistemas, aplicaciones y servicios informáticos.
\item[\textbf{CE15}] Capacidad para la creación y explotación de entornos virtuales.


\end{itemize}

La competencia \textbf{CE1} se ha alcanzado a través de la integración de
diversas tecnologías en distintos ámbitos. Aplicaciones, servicios cloud
ofrecidos por Amazon Web Services, integración y creación de elementos para
frameworks y aplicaciones \textit{end to end} que involucran aspectos desde
enrutamiento de datos hasta visualización de los mismos. 

La competencia \textbf{CE4} se ha logrado mediante el diseño e implementación de
la arquitectura elaborada en este TFM, así como la configuración y despliegue
de los servidores y almacenamiento distribuido usando tecnologías cloud,
securizándolas, e incluyendo elementos en el \textit{end to end} del
ecosistema Apache Hadoop. 


Se ha alcanzado la competencia \textbf{CE6} mediante la rigurosa fase de calidad
y pruebas, \acf{QA}, ya sea a través de test unitarios como por test
automatizados por parte de los proveedores de la nube. Se ha sometido a todo artefacto presente en el
trabajo a un riguroso proceso de calidad. Igualmente, la calidad de los datos ha tenido especial relevancia debido al
problema que se resuelve en este proyecto, desarrollando métricas para
evaluarla. 


Para la competencia \textbf{CE14} se ha hecho especial hincapié en la
visualización de los resultados de las evaluaciones así como recalcar la
importancia del visionado del procesamiento de los datos a través de
herramientas conceptuales tales como \acf{DAG}. 

La competencia \textbf{CE15} ha tenido un peso especial para el desarrollo de
este proyecto debido a la necesidad de virtualización existente para cada uno de
los componentes. Se ha alcanzado la competencia a través de la virtualización de
diversos servicios, tanto locales como en la nube. 

\section{Estructura del documento}

La forma en la que se ha organizado el presente documento se expone a
continuación: 

\begin{definitionlist}
\item[Capítulo \ref{chap:Introduccion}: \nameref{chap:Introduccion}] En este
  apartado se introduce el problema y se plantea el trabajo en base a los
  objetivos fijados. 


\item[Capítulo \ref{chap:objetivos}: \nameref{chap:objetivos}] En este capítulo
  se describe el principal objetivo del \acs{TFM} así como un conjunto de
  objetivos parciales que es necesario alcanzar para cubrir el objetivo
  final. 

\item[Capítulo \ref{chap:estadoarte}: \nameref{chap:estadoarte}] Esta sección
  introducirá los conceptos más importantes tratados en el documento y el
  proyecto, acompañado de conceptos y definiciones. Incluirá referencias al
  ámbito de la calidad de los datos, la Web Semántica y las tecnologías
  asociadas a ésta. 

\item[Capítulo \ref{chap:metodologia}: \nameref{chap:metodologia}] Se expondrá
  detalladamente cómo se ha utilizado la metodología de desarrollo elegida para la realización del \acs{TFM}.

\item[Capítulo \ref{chap:resultados}: \nameref{chap:resultados}] En este
  capítulo se expondrán los resultados obtenidos durante las diferentes
  iteraciones que se han llevado a cabo durante el desarrollo del
  \acs{TFM}. 

\item[Capítulo \ref{chap:conclusiones}: \nameref{chap:conclusiones}] En este
  capítulo se expondrán las conclusiones que se han obtenido tras la realización
  de este \acs{TFM} además de una serie de propuestas de trabajo futuro. 

%\item[Anexo \ref{chap:ontologia}: \nameref{chap:ontologia}] Se
%  corresponde con el listado de código de las ontologías desarrolladas para formalizar
%  los resultados de evaluaciones de calidad de datos enlazados. 

\end{definitionlist}




